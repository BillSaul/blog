---
title: 使用Docker在本地快速启动一个DeepSeek-R1模型
author:
  name: 薄荷屋
  url: https://www.meowpass.com
category:
  - 大型语言模型
tag:
  - Docker
  - DeepSeek
  - LLM
  - 大型语言模型
date: 2025-02-11 11:05:38
permalink: /pages/bcbfc5/
---



> [!NOTE]
> 
> 使用 [ollama](https://ollama.com/) 启动模型；使用 [open-webui](https://github.com/open-webui/open-webui) 作为UI界面。

<!-- more -->

## 1. 准备

> [!TIP]
>
> 请保持网络通常，避免下载不动或者下载不了哦 😉

### 1.1 安装 Docker

进入[官网](https://www.docker.com/)，下载安装包并安装。

### 1.2 启动相关容器

创建一个文件夹，在里面创建文件 `compose.yml`：

```
name: llm

services:
  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    gpus:
      - driver: nvidia
        count: "all"
        capabilities: [gpu]

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    depends_on:
      - ollama
    ports:
      - "31000:8080"
    extra_hosts:
      - host.docker.internal:host-gateway
    volumes:
      - open-webui:/app/backend/data

volumes:
  ollama:
  open-webui:
```

然后在刚才新建的文件夹中启动一个终端来执行相关命令*（Windows用户可以直接在资源管理器顶部的地址栏中输入`cmd`）*

启动服务：

```shell
docker compose up -d
```

停止服务：

```shell
docker compose down
```

更新 ollama 或 open-webui 的版本，依次执行：

```shell
docker compose down

docker compose pull

docker compose up -d
```

查看运行日志：

``` shell
docker compose logs -f
```

## 2. 使用

浏览器访问：`localhost:31000`。

注册的第一个用户为管理员账户，登录后下载 deepseek-r1 模型，根据自己电脑的硬件配置选择合适的模型：`deepseek-r1:1.5b`、`deepseek-r1:7b`、`deepseek-r1:8b`、`deepseek-r1:14b`、`deepseek-r1:32b`、`deepseek-r1:70b`、`deepseek-r1:671b`。

![](/assets/page-img/2025/20250211/ajopp-n8c9p.webp)

等待下载完成，然后就可以选择已经下载的模型进行对话：

![](/assets/page-img/2025/20250211/a8hcb-v661x.webp)
