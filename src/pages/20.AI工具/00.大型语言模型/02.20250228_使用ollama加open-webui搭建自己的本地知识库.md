---
title: 使用ollama加open-webui搭建自己的本地知识库
author:
  name: 薄荷屋
  url: https://www.meowpass.com
category:
  - 大型语言模型
tag:
  - Docker
  - DeepSeek
  - LLM
  - 大型语言模型
  - RAG
date: 2025-02-28 11:31:11
permalink: /pages/f33b3b/
---



之前用 Docker 部署部署了本地大模型：[使用Docker在本地快速启动一个DeepSeek-R1模型](/pages/bcbfc5/)

这篇将会使用 open-webui 搭建自己的本地知识库。

## 1. 准备工作

首先我们需要先修改一下 open-webui 默认的 `语义向量模型引擎` 和 `语义向量模型`。默认使用的 `语义向量模型引擎` 是”**sentence-transformers**“，但是我测试下来发现效果并不是很好。

在 管理员面板 > 设置 > 文档 中，将 `语义向量模型引擎` 改为：Ollama，将 `语义向量模型` 改为：bge-m3。

![](/assets/page-img/2025/20250228/al8ot-p20or.webp)

BGE-M3（M3-Embedding）是由北京智源人工智能研究院（BAAI）和中国科学技术大学联合推出的多语言文本嵌入模型。该模型旨在提供多语言、多功能和多粒度的文本嵌入解决方案。

然后下载 `语义向量模型` ，直接用 Ollama 下载。

![](/assets/page-img/2025/20250228/a9grr-u3adj.webp)

## 2. 创建知识库

点击左侧的工作空间，选择知识库，点击添加按钮添加一个知识库。

![](/assets/page-img/2025/20250228/aowxj-neefv.webp)

![](/assets/page-img/2025/20250228/a3p07-0cjuo.webp)

完成后，点击 ”**创建知识**“。

创建好后，就可以直接把相关的文件拖拽进去。这里我上传了几篇我博客的文章来测试。

![](/assets/page-img/2025/20250228/ae6pn-y4a2e.webp)

## 3. 创建新模型

创建好知识库后，就可以创建一个定制化的对话模型，把知识库添加进去，这样每次对话选择这个模型，模型就会自动检索知识库中的知识进行回答了。

![](/assets/page-img/2025/20250228/am28k-86k6e.webp)

基础模型选择一个合适的模型，这里我选择 `deepseek-r1：7b`。**注意**：不要选择前面下载的bge-m3。如果你还没有其它的模型，请按照这篇教程下载模型：[使用Docker在本地快速启动一个DeepSeek-R1模型](/pages/bcbfc5/#_2-使用)

![](/assets/page-img/2025/20250228/a5w4x-u9j6a.webp)

## 4. 使用

点击左上角的”新对话“，选择刚才创建的模型，然后就可以开始使用了 🎉。

![](/assets/page-img/2025/20250228/accq6-4v0sh.webp)

尝试问它一个问题，可以看到模型回复的内容就是来自我刚才上传的博客文章中的内容。

![](/assets/page-img/2025/20250228/axoiz-klom4.webp)

![](/assets/page-img/2025/20250228/a5thr-7ez7o.webp)